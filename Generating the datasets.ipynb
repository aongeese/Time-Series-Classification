{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle \n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline1 = pd.DataFrame([])\n",
    "baseline2= pd.DataFrame([])\n",
    "baseline3 = pd.DataFrame([])\n",
    "baselineFinal = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CYLINDER=1\n",
    "BELL=2\n",
    "FUNNEL=3\n",
    "\n",
    "def Baselinekeoghcbf(o, tslength=128):\n",
    "  base = tslength / 8\n",
    "  \"\"\"\"\n",
    "  This is the Cylinder-Bell-Funnel (CBF)\n",
    "   N. Saito, Local feature extraction and its application\n",
    "  using a library of bases. Ph.D. thesis, Department of Mathematics,\n",
    "  Yale University, 1994.\"\"\"\n",
    "  a = random.randint(base,base*2)\n",
    "  b = base*2 + random.randint(base*2,base*6)\n",
    "  n = random.normalvariate(0.0,1.0)\n",
    "  def xab(t):\n",
    "    if ( (t>=a) and (t <=b) ):\n",
    "      return 1.0\n",
    "    return 0.0\n",
    "  if(o == CYLINDER):\n",
    "    return [ (6+n)*xab(t) + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]\n",
    "  elif(o == BELL) :\n",
    "    return [ (6+n)*xab(t) *(t - a) / (b - a)  + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]    \n",
    "  elif (o == FUNNEL):\n",
    "    return [ (6+n)*xab(t) *(b - t) / (b - a)  + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]    \n",
    "  else :\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,400):\n",
    "    baseline1 = baseline1.append(pd.DataFrame(Baselinekeoghcbf(1)).T)\n",
    "    baseline2 = baseline2.append(pd.DataFrame(Baselinekeoghcbf(2)).T)\n",
    "    baseline3 = baseline3.append(pd.DataFrame(Baselinekeoghcbf(3)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline3.insert(0, 'class', 3)\n",
    "baseline2.insert(0, 'class', 2)\n",
    "baseline1.insert(0, 'class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baselineFinal = baselineFinal.append(pd.DataFrame(baseline1))\n",
    "baselineFinal = baselineFinal.append(pd.DataFrame(baseline2))\n",
    "baselineFinal = baselineFinal.append(pd.DataFrame(baseline3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baselineFinal = baselineFinal.sample(frac=1).reset_index(drop=True)#suffles the rows in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = baselineFinal.groupby(['class']).head(100)\n",
    "test = baselineFinal.drop(baselineFinal.groupby(['class']).head(100).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('baseline_TEST', sep=',', index=False, header=False)#saves the dataset to file named baseline_test\n",
    "train.to_csv('baseline_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CYLINDER=1\n",
    "BELL=2\n",
    "FUNNEL=3\n",
    "\n",
    "def Gaussiankeoghcbf(o,sig, tslength=128):\n",
    "  base = tslength / 8\n",
    "  \"\"\"\n",
    "  This is the Cylinder-Bell-Funnel (CBF)\n",
    "   N. Saito, Local feature extraction and its application\n",
    "  using a library of bases. Ph.D. thesis, Department of Mathematics,\n",
    "  Yale University, 1994.\"\"\"\n",
    "  a = random.randint(base,base*2)\n",
    "  b = base*2 + random.randint(base*2,base*6)\n",
    "  n = random.normalvariate(0.0,1.0)\n",
    "  def xab(t):\n",
    "    if ( (t>=a) and (t <=b) ):\n",
    "      return 1.0\n",
    "    return 0.0\n",
    "  if(o == CYLINDER):\n",
    "    return [ (6+n)*xab(t) + random.normalvariate(0.0,sig) for t in range(1,tslength + 1)]\n",
    "  elif(o == BELL) :\n",
    "    return [ (6+n)*xab(t) *(t - a) / (b - a)  + random.normalvariate(0.0,sig) for t in range(1,tslength + 1)]    \n",
    "  elif (o == FUNNEL):\n",
    "    return [ (6+n)*xab(t) *(b - t) / (b - a)  + random.normalvariate(0.0,sig) for t in range(1,tslength + 1)]    \n",
    "  else :\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Noise 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss20test1 = pd.DataFrame([])\n",
    "gauss20test2 = pd.DataFrame([])\n",
    "gauss20test3 = pd.DataFrame([])\n",
    "g20test = pd.DataFrame([])\n",
    "\n",
    "gauss20train1 = pd.DataFrame([])\n",
    "gauss20train2 = pd.DataFrame([])\n",
    "gauss20train3 = pd.DataFrame([])\n",
    "g20train = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,60):\n",
    "    gauss20test1 = gauss20test1.append(pd.DataFrame(Gaussiankeoghcbf(1,3)).T)#adds noisy time series to the dataset\n",
    "    gauss20test2 = gauss20test2.append(pd.DataFrame(Gaussiankeoghcbf(2,3)).T)\n",
    "    gauss20test3 = gauss20test3.append(pd.DataFrame(Gaussiankeoghcbf(3,3)).T)\n",
    "\n",
    "for i in range(0,240):\n",
    "    gauss20test1 = gauss20test1.append(pd.DataFrame(Gaussiankeoghcbf(1,1)).T)#adds baseline time series to the dataset\n",
    "    gauss20test2 = gauss20test2.append(pd.DataFrame(Gaussiankeoghcbf(2,1)).T)\n",
    "    gauss20test3 = gauss20test3.append(pd.DataFrame(Gaussiankeoghcbf(3,1)).T)\n",
    "    \n",
    "    \n",
    "for i in range(0,20):\n",
    "    gauss20train1 = gauss20train1.append(pd.DataFrame(Gaussiankeoghcbf(1,3)).T)\n",
    "    gauss20train2 = gauss20train2.append(pd.DataFrame(Gaussiankeoghcbf(2,3)).T)\n",
    "    gauss20train3 = gauss20train3.append(pd.DataFrame(Gaussiankeoghcbf(3,3)).T)\n",
    "    \n",
    "for i in range(0,80):\n",
    "    gauss20train1 = gauss20train1.append(pd.DataFrame(Gaussiankeoghcbf(1,1)).T)\n",
    "    gauss20train2 = gauss20train2.append(pd.DataFrame(Gaussiankeoghcbf(2,1)).T)\n",
    "    gauss20train3 = gauss20train3.append(pd.DataFrame(Gaussiankeoghcbf(3,1)).T)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss20test3.insert(0, 'class', 3)#adds column to the begining of the dataset contain 3 for all rows\n",
    "gauss20test2.insert(0, 'class', 2)\n",
    "gauss20test1.insert(0, 'class', 1)\n",
    "\n",
    "gauss20train3.insert(0, 'class', 3)\n",
    "gauss20train2.insert(0, 'class', 2)\n",
    "gauss20train1.insert(0, 'class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g20train = g20train.append(pd.DataFrame(gauss20train1))#add gauss20train1 dataset to g20train dataset\n",
    "g20train = g20train.append(pd.DataFrame(gauss20train2))\n",
    "g20train = g20train.append(pd.DataFrame(gauss20train3))\n",
    "\n",
    "g20test = g20test.append(pd.DataFrame(gauss20test1))\n",
    "g20test = g20test.append(pd.DataFrame(gauss20test2))\n",
    "g20test = g20test.append(pd.DataFrame(gauss20test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g20test = g20test.sample(frac=1).reset_index(drop=True)\n",
    "g20train = g20train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g20test.to_csv('Gaussian20_TEST', sep=',', index=False, header=False)\n",
    "g20train.to_csv('Gaussian20_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Noise 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss40test1 = pd.DataFrame([])\n",
    "gauss40test2 = pd.DataFrame([])\n",
    "gauss40test3 = pd.DataFrame([])\n",
    "g40test = pd.DataFrame([])\n",
    "\n",
    "gauss40train1 = pd.DataFrame([])\n",
    "gauss40train2 = pd.DataFrame([])\n",
    "gauss40train3 = pd.DataFrame([])\n",
    "g40train = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,120):\n",
    "    gauss40test1 = gauss40test1.append(pd.DataFrame(Gaussiankeoghcbf(1,3)).T)\n",
    "    gauss40test2 = gauss40test2.append(pd.DataFrame(Gaussiankeoghcbf(2,3)).T)\n",
    "    gauss40test3 = gauss40test3.append(pd.DataFrame(Gaussiankeoghcbf(3,3)).T)\n",
    "\n",
    "for i in range(0,180):\n",
    "    gauss40test1 = gauss40test1.append(pd.DataFrame(Gaussiankeoghcbf(1,1)).T)\n",
    "    gauss40test2 = gauss40test2.append(pd.DataFrame(Gaussiankeoghcbf(2,1)).T)\n",
    "    gauss40test3 = gauss40test3.append(pd.DataFrame(Gaussiankeoghcbf(3,1)).T)\n",
    "    \n",
    "    \n",
    "for i in range(0,40):\n",
    "    gauss40train1 = gauss40train1.append(pd.DataFrame(Gaussiankeoghcbf(1,3)).T)\n",
    "    gauss40train2 = gauss40train2.append(pd.DataFrame(Gaussiankeoghcbf(2,3)).T)\n",
    "    gauss40train3 = gauss40train3.append(pd.DataFrame(Gaussiankeoghcbf(3,3)).T)\n",
    "    \n",
    "for i in range(0,60):\n",
    "    gauss40train1 = gauss40train1.append(pd.DataFrame(Gaussiankeoghcbf(1,1)).T)\n",
    "    gauss40train2 = gauss40train2.append(pd.DataFrame(Gaussiankeoghcbf(2,1)).T)\n",
    "    gauss40train3 = gauss40train3.append(pd.DataFrame(Gaussiankeoghcbf(3,1)).T)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss40test3.insert(0, 'class', 3)\n",
    "gauss40test2.insert(0, 'class', 2)\n",
    "gauss40test1.insert(0, 'class', 1)\n",
    "\n",
    "gauss40train3.insert(0, 'class', 3)\n",
    "gauss40train2.insert(0, 'class', 2)\n",
    "gauss40train1.insert(0, 'class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g40train = g40train.append(pd.DataFrame(gauss40train1))\n",
    "g40train = g40train.append(pd.DataFrame(gauss40train2))\n",
    "g40train = g40train.append(pd.DataFrame(gauss40train3))\n",
    "\n",
    "g40test = g40test.append(pd.DataFrame(gauss40test1))\n",
    "g40test = g40test.append(pd.DataFrame(gauss40test2))\n",
    "g40test = g40test.append(pd.DataFrame(gauss40test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g40test = g40test.sample(frac=1).reset_index(drop=True)\n",
    "g40train = g40train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g40test.to_csv('Gaussian40_TEST', sep=',', index=False, header=False)\n",
    "g40train.to_csv('Gaussian40_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Noise 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss60test1 = pd.DataFrame([])\n",
    "gauss60test2 = pd.DataFrame([])\n",
    "gauss60test3 = pd.DataFrame([])\n",
    "g60test = pd.DataFrame([])\n",
    "\n",
    "gauss60train1 = pd.DataFrame([])\n",
    "gauss60train2 = pd.DataFrame([])\n",
    "gauss60train3 = pd.DataFrame([])\n",
    "g60train = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,180):\n",
    "    gauss60test1 = gauss60test1.append(pd.DataFrame(Gaussiankeoghcbf(1,3)).T)\n",
    "    gauss60test2 = gauss60test2.append(pd.DataFrame(Gaussiankeoghcbf(2,3)).T)\n",
    "    gauss60test3 = gauss60test3.append(pd.DataFrame(Gaussiankeoghcbf(3,3)).T)\n",
    "\n",
    "for i in range(0,120):\n",
    "    gauss60test1 = gauss60test1.append(pd.DataFrame(Gaussiankeoghcbf(1,1)).T)\n",
    "    gauss60test2 = gauss60test2.append(pd.DataFrame(Gaussiankeoghcbf(2,1)).T)\n",
    "    gauss60test3 = gauss60test3.append(pd.DataFrame(Gaussiankeoghcbf(3,1)).T)\n",
    "    \n",
    "    \n",
    "for i in range(0,60):\n",
    "    gauss60train1 = gauss60train1.append(pd.DataFrame(Gaussiankeoghcbf(1,3)).T)\n",
    "    gauss60train2 = gauss60train2.append(pd.DataFrame(Gaussiankeoghcbf(2,3)).T)\n",
    "    gauss60train3 = gauss60train3.append(pd.DataFrame(Gaussiankeoghcbf(3,3)).T)\n",
    "    \n",
    "for i in range(0,40):\n",
    "    gauss60train1 = gauss60train1.append(pd.DataFrame(Gaussiankeoghcbf(1,1)).T)\n",
    "    gauss60train2 = gauss60train2.append(pd.DataFrame(Gaussiankeoghcbf(2,1)).T)\n",
    "    gauss60train3 = gauss60train3.append(pd.DataFrame(Gaussiankeoghcbf(3,1)).T)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gauss60test3.insert(0, 'class', 3)\n",
    "gauss60test2.insert(0, 'class', 2)\n",
    "gauss60test1.insert(0, 'class', 1)\n",
    "\n",
    "gauss60train3.insert(0, 'class', 3)\n",
    "gauss60train2.insert(0, 'class', 2)\n",
    "gauss60train1.insert(0, 'class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g60train = g60train.append(pd.DataFrame(gauss60train1))\n",
    "g60train = g60train.append(pd.DataFrame(gauss60train2))\n",
    "g60train = g60train.append(pd.DataFrame(gauss60train3))\n",
    "\n",
    "g60test = g60test.append(pd.DataFrame(gauss60test1))\n",
    "g60test = g60test.append(pd.DataFrame(gauss60test2))\n",
    "g60test = g60test.append(pd.DataFrame(gauss60test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g60test = g60test.sample(frac=1).reset_index(drop=True)\n",
    "g60train = g60train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g60test.to_csv('Gaussian60_TEST', sep=',', index=False, header=False)\n",
    "g60train.to_csv('Gaussian60_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variable length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "CYLINDER=1\n",
    "BELL=2\n",
    "FUNNEL=3\n",
    "\n",
    "def VLkeoghcbf(o,length):\n",
    "  tslength = random.randint(128,length)\n",
    "  base = 128 / 8\n",
    "  \"\"\"\n",
    "  This is the Cylinder-Bell-Funnel (CBF)\n",
    "   N. Saito, Local feature extraction and its application\n",
    "  using a library of bases. Ph.D. thesis, Department of Mathematics,\n",
    "  Yale University, 1994.\"\"\"\n",
    "  a = random.randint(base,base*2)\n",
    "  b = base*2 + random.randint(base*2,base*6)\n",
    "  n = random.normalvariate(0.0,1.0)\n",
    "  def xab(t):\n",
    "    if ( (t>=a) and (t <=b) ):\n",
    "      return 1.0\n",
    "    return 0.0\n",
    "  if(o == CYLINDER):\n",
    "    return [ (6+n)*xab(t) + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]\n",
    "  elif(o == BELL) :\n",
    "    return [ (6+n)*xab(t) *(t - a) / (b - a)  + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]    \n",
    "  elif (o == FUNNEL):\n",
    "    return [ (6+n)*xab(t) *(b - t) / (b - a)  + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]    \n",
    "  else :\n",
    "    return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Length at 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TEST20.txt', 'w') as out_file:\n",
    "    for i in range(0,60):\n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,256))# writes the number 1 to represent the class, followed by the time series\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "      \n",
    "with open('TEST20.txt', 'a') as out_file:\n",
    "    for i in range(0,240):        \n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,128))\n",
    "        out_file.write(out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TRAIN20.txt', 'w') as out_file:\n",
    "    for i in range(0,20):\n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        \n",
    "with open('TRAIN20.txt', 'a') as out_file:\n",
    "    for i in range(0,80):       \n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,128))\n",
    "        out_file.write(out_string)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'TRAIN20.txt', 'r') as infile, open(r'VLength20_TRAIN', 'w') as outfile:\n",
    "    \n",
    "    \n",
    "        data = infile.read()\n",
    "        data = data.replace(\"[\", \" \")#this removes the opening bracket from each line we add to the file\n",
    "        data = data.replace(\"]\", \" \\n\")\n",
    "        outfile.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'TEST20.txt', 'r') as infile, open(r'VLength20_TEST', 'w') as outfile:\n",
    "    \n",
    "    \n",
    "        data = infile.read()\n",
    "        data = data.replace(\"[\", \" \")#this removes the opening bracket from each line we add to the file\n",
    "        data = data.replace(\"]\", \" \\n\")\n",
    "        outfile.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Length at 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('TEST40.txt', 'w') as out_file:\n",
    "    for i in range(0,120):\n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "      \n",
    "with open('TEST40.txt', 'a') as out_file:\n",
    "    for i in range(0,180):        \n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,128))\n",
    "        out_file.write(out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TRAIN40.txt', 'w') as out_file:\n",
    "    for i in range(0,40):\n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        \n",
    "with open('TRAIN40.txt', 'a') as out_file:\n",
    "    for i in range(0,60):       \n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,128))\n",
    "        out_file.write(out_string)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'TRAIN40.txt', 'r') as infile, open(r'VLength40_TRAIN', 'w') as outfile:\n",
    "    \n",
    "    \n",
    "        data = infile.read()\n",
    "        data = data.replace(\"[\", \" \")\n",
    "        data = data.replace(\"]\", \" \\n\")\n",
    "        outfile.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'TEST40.txt', 'r') as infile, open(r'VLength40_TEST', 'w') as outfile:\n",
    "    \n",
    "    \n",
    "        data = infile.read()\n",
    "        data = data.replace(\"[\", \" \")\n",
    "        data = data.replace(\"]\", \" \\n\")\n",
    "        outfile.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Length at 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TEST60.txt', 'w') as out_file:\n",
    "    for i in range(0,180):\n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "      \n",
    "with open('TEST60.txt', 'a') as out_file:\n",
    "    for i in range(0,120):        \n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,128))\n",
    "        out_file.write(out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TRAIN60.txt', 'w') as out_file:\n",
    "    for i in range(0,60):\n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,256))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        \n",
    "with open('TRAIN60.txt', 'a') as out_file:\n",
    "    for i in range(0,40):       \n",
    "        out_string = \"\"\n",
    "        out_string = \"1,\" + str(VLkeoghcbf(1,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"2,\" + str(VLkeoghcbf(2,128))\n",
    "        out_file.write(out_string)\n",
    "        \n",
    "        out_string = \"\"\n",
    "        out_string = \"3,\" + str(VLkeoghcbf(3,128))\n",
    "        out_file.write(out_string)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'TRAIN60.txt', 'r') as infile, open(r'VLength60_TRAIN', 'w') as outfile:\n",
    "    \n",
    "    \n",
    "        data = infile.read()\n",
    "        data = data.replace(\"[\", \" \")#this removes the opening bracket from each line we add to the file\n",
    "        data = data.replace(\"]\", \" \\n\")\n",
    "        outfile.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'TEST60.txt', 'r') as infile, open(r'VLength60_TEST', 'w') as outfile:\n",
    "    \n",
    "    \n",
    "        data = infile.read()\n",
    "        data = data.replace(\"[\", \" \")#this removes the opening bracket from each line we add to the file\n",
    "        data = data.replace(\"]\", \" \\n\")\n",
    "        outfile.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Amplitude Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CYLINDER=1\n",
    "BELL=2\n",
    "FUNNEL=3\n",
    "\n",
    "def Ampkeoghcbf(o,sig, tslength=128):\n",
    "  base = tslength / 8\n",
    "  \"\"\"\n",
    "  This is the Cylinder-Bell-Funnel (CBF)\n",
    "   N. Saito, Local feature extraction and its application\n",
    "  using a library of bases. Ph.D. thesis, Department of Mathematics,\n",
    "  Yale University, 1994.\"\"\"\n",
    "  a = random.randint(base,base*2)\n",
    "  b = base*2 + random.randint(base*2,base*6)\n",
    "  n = random.normalvariate(0.0,sig)\n",
    "  def xab(t):\n",
    "    if ( (t>=a) and (t <=b) ):\n",
    "      return 1.0\n",
    "    return 0.0\n",
    "  if(o == CYLINDER):\n",
    "    return [ (6+n)*xab(t) + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]\n",
    "  elif(o == BELL) :\n",
    "    return [ (6+n)*xab(t) *(t - a) / (b - a)  + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]    \n",
    "  elif (o == FUNNEL):\n",
    "    return [ (6+n)*xab(t) *(b - t) / (b - a)  + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]    \n",
    "  else :\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amplitude Scaling at 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Amp20test1 = pd.DataFrame([])\n",
    "Amp20test2 = pd.DataFrame([])\n",
    "Amp20test3 = pd.DataFrame([])\n",
    "A20test = pd.DataFrame([])\n",
    "\n",
    "Amp20train1 = pd.DataFrame([])\n",
    "Amp20train2 = pd.DataFrame([])\n",
    "Amp20train3 = pd.DataFrame([])\n",
    "A20train = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,60):\n",
    "    Amp20test1 = Amp20test1.append(pd.DataFrame(Ampkeoghcbf(1,3)).T)\n",
    "    Amp20test2 = Amp20test2.append(pd.DataFrame(Ampkeoghcbf(2,3)).T)\n",
    "    Amp20test3 = Amp20test3.append(pd.DataFrame(Ampkeoghcbf(3,3)).T)\n",
    "\n",
    "for i in range(0,240):\n",
    "    Amp20test1 = Amp20test1.append(pd.DataFrame(Ampkeoghcbf(1,1)).T)\n",
    "    Amp20test2 = Amp20test2.append(pd.DataFrame(Ampkeoghcbf(2,1)).T)\n",
    "    Amp20test3 = Amp20test3.append(pd.DataFrame(Ampkeoghcbf(3,1)).T)\n",
    "    \n",
    "    \n",
    "for i in range(0,20):\n",
    "    Amp20train1 = Amp20train1.append(pd.DataFrame(Ampkeoghcbf(1,3)).T)\n",
    "    Amp20train2 = Amp20train2.append(pd.DataFrame(Ampkeoghcbf(2,3)).T)\n",
    "    Amp20train3 = Amp20train3.append(pd.DataFrame(Ampkeoghcbf(3,3)).T)\n",
    "    \n",
    "for i in range(0,80):\n",
    "    Amp20train1 = Amp20train1.append(pd.DataFrame(Ampkeoghcbf(1,1)).T)\n",
    "    Amp20train2 = Amp20train2.append(pd.DataFrame(Ampkeoghcbf(2,1)).T)\n",
    "    Amp20train3 = Amp20train3.append(pd.DataFrame(Ampkeoghcbf(3,1)).T)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Amp20test3.insert(0, 'class', 3)\n",
    "Amp20test2.insert(0, 'class', 2)\n",
    "Amp20test1.insert(0, 'class', 1)\n",
    "\n",
    "Amp20train3.insert(0, 'class', 3)\n",
    "Amp20train2.insert(0, 'class', 2)\n",
    "Amp20train1.insert(0, 'class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A20train = A20train.append(pd.DataFrame(Amp20train1))\n",
    "A20train = A20train.append(pd.DataFrame(Amp20train2))\n",
    "A20train = A20train.append(pd.DataFrame(Amp20train3))\n",
    "\n",
    "A20test = A20test.append(pd.DataFrame(Amp20test1))\n",
    "A20test = A20test.append(pd.DataFrame(Amp20test2))\n",
    "A20test = A20test.append(pd.DataFrame(Amp20test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A20test = A20test.sample(frac=1).reset_index(drop=True)\n",
    "A20train = A20train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A20test.to_csv('AmpScaling20_TEST', sep=',', index=False, header=False)\n",
    "A20train.to_csv('AmpScaling20_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amplitude Scaling at 40% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Amp40test1 = pd.DataFrame([])\n",
    "Amp40test2 = pd.DataFrame([])\n",
    "Amp40test3 = pd.DataFrame([])\n",
    "A40test = pd.DataFrame([])\n",
    "\n",
    "Amp40train1 = pd.DataFrame([])\n",
    "Amp40train2 = pd.DataFrame([])\n",
    "Amp40train3 = pd.DataFrame([])\n",
    "A40train = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,120):\n",
    "    Amp40test1 = Amp40test1.append(pd.DataFrame(Ampkeoghcbf(1,3)).T)\n",
    "    Amp40test2 = Amp40test2.append(pd.DataFrame(Ampkeoghcbf(2,3)).T)\n",
    "    Amp40test3 = Amp40test3.append(pd.DataFrame(Ampkeoghcbf(3,3)).T)\n",
    "\n",
    "for i in range(0,180):\n",
    "    Amp40test1 = Amp40test1.append(pd.DataFrame(Ampkeoghcbf(1,1)).T)\n",
    "    Amp40test2 = Amp40test2.append(pd.DataFrame(Ampkeoghcbf(2,1)).T)\n",
    "    Amp40test3 = Amp40test3.append(pd.DataFrame(Ampkeoghcbf(3,1)).T)\n",
    "    \n",
    "    \n",
    "for i in range(0,40):\n",
    "    Amp40train1 = Amp40train1.append(pd.DataFrame(Ampkeoghcbf(1,3)).T)\n",
    "    Amp40train2 = Amp40train2.append(pd.DataFrame(Ampkeoghcbf(2,3)).T)\n",
    "    Amp40train3 = Amp40train3.append(pd.DataFrame(Ampkeoghcbf(3,3)).T)\n",
    "    \n",
    "for i in range(0,60):\n",
    "    Amp40train1 = Amp40train1.append(pd.DataFrame(Ampkeoghcbf(1,1)).T)\n",
    "    Amp40train2 = Amp40train2.append(pd.DataFrame(Ampkeoghcbf(2,1)).T)\n",
    "    Amp40train3 = Amp40train3.append(pd.DataFrame(Ampkeoghcbf(3,1)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Amp40test3.insert(0, 'class', 3)\n",
    "Amp40test2.insert(0, 'class', 2)\n",
    "Amp40test1.insert(0, 'class', 1)\n",
    "\n",
    "Amp40train3.insert(0, 'class', 3)\n",
    "Amp40train2.insert(0, 'class', 2)\n",
    "Amp40train1.insert(0, 'class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A40train = A40train.append(pd.DataFrame(Amp40train1))\n",
    "A40train = A40train.append(pd.DataFrame(Amp40train2))\n",
    "A40train = A40train.append(pd.DataFrame(Amp40train3))\n",
    "\n",
    "A40test = A40test.append(pd.DataFrame(Amp40test1))\n",
    "A40test = A40test.append(pd.DataFrame(Amp40test2))\n",
    "A40test = A40test.append(pd.DataFrame(Amp40test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A40test = A40test.sample(frac=1).reset_index(drop=True)\n",
    "A40train = A40train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A40test.to_csv('AmpScaling40_TEST', sep=',', index=False, header=False)\n",
    "A40train.to_csv('AmpScaling40_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amplitude Scaling at 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Amp60test1 = pd.DataFrame([])\n",
    "Amp60test2 = pd.DataFrame([])\n",
    "Amp60test3 = pd.DataFrame([])\n",
    "A60test = pd.DataFrame([])\n",
    "\n",
    "Amp60train1 = pd.DataFrame([])\n",
    "Amp60train2 = pd.DataFrame([])\n",
    "Amp60train3 = pd.DataFrame([])\n",
    "A60train = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,180):\n",
    "    Amp60test1 = Amp60test1.append(pd.DataFrame(Ampkeoghcbf(1,3)).T)\n",
    "    Amp60test2 = Amp60test2.append(pd.DataFrame(Ampkeoghcbf(2,3)).T)\n",
    "    Amp60test3 = Amp60test3.append(pd.DataFrame(Ampkeoghcbf(3,3)).T)\n",
    "\n",
    "for i in range(0,120):\n",
    "    Amp60test1 = Amp60test1.append(pd.DataFrame(Ampkeoghcbf(1,1)).T)\n",
    "    Amp60test2 = Amp60test2.append(pd.DataFrame(Ampkeoghcbf(2,1)).T)\n",
    "    Amp60test3 = Amp60test3.append(pd.DataFrame(Ampkeoghcbf(3,1)).T)\n",
    "    \n",
    "    \n",
    "for i in range(0,60):\n",
    "    Amp60train1 = Amp60train1.append(pd.DataFrame(Ampkeoghcbf(1,3)).T)\n",
    "    Amp60train2 = Amp60train2.append(pd.DataFrame(Ampkeoghcbf(2,3)).T)\n",
    "    Amp60train3 = Amp60train3.append(pd.DataFrame(Ampkeoghcbf(3,3)).T)\n",
    "    \n",
    "for i in range(0,40):\n",
    "    Amp60train1 = Amp60train1.append(pd.DataFrame(Ampkeoghcbf(1,1)).T)\n",
    "    Amp60train2 = Amp60train2.append(pd.DataFrame(Ampkeoghcbf(2,1)).T)\n",
    "    Amp60train3 = Amp60train3.append(pd.DataFrame(Ampkeoghcbf(3,1)).T)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Amp60test3.insert(0, 'class', 3)\n",
    "Amp60test2.insert(0, 'class', 2)\n",
    "Amp60test1.insert(0, 'class', 1)\n",
    "\n",
    "Amp60train3.insert(0, 'class', 3)\n",
    "Amp60train2.insert(0, 'class', 2)\n",
    "Amp60train1.insert(0, 'class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A60train = A60train.append(pd.DataFrame(Amp60train1))\n",
    "A60train = A60train.append(pd.DataFrame(Amp60train2))\n",
    "A60train = A60train.append(pd.DataFrame(Amp60train3))\n",
    "\n",
    "A60test = A60test.append(pd.DataFrame(Amp60test1))\n",
    "A60test = A60test.append(pd.DataFrame(Amp60test2))\n",
    "A60test = A60test.append(pd.DataFrame(Amp60test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A60test = A60test.sample(frac=1).reset_index(drop=True)\n",
    "A60train = A60train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A60test.to_csv('AmpScaling60_TEST', sep=',', index=False, header=False)\n",
    "A60train.to_csv('AmpScaling60_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Shape Time Warping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CYLINDER=1\n",
    "BELL=2\n",
    "FUNNEL=3\n",
    "\n",
    "def keoghcbfSS(o,ai,aii,bi,bii,tslength=128):\n",
    "  base = tslength / 8\n",
    "  \"\"\"\n",
    "  This is the Cylinder-Bell-Funnel (CBF)\n",
    "   N. Saito, Local feature extraction and its application\n",
    "  using a library of bases. Ph.D. thesis, Department of Mathematics,\n",
    "  Yale University, 1994.\"\"\"\n",
    "  a = random.randint(ai,aii)\n",
    "  b = aii + random.randint(bi,bii)\n",
    "  n = random.normalvariate(0.0,1.0)\n",
    "  def xab(t):\n",
    "    if ( (t>=a) and (t <=b) ):\n",
    "      return 1.0\n",
    "    return 0.0\n",
    "  if(o == CYLINDER):\n",
    "    return [ (6+n)*xab(t) + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]\n",
    "  elif(o == BELL) :\n",
    "    return [ (6+n)*xab(t) *(t - a) / (b - a)  + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]    \n",
    "  elif (o == FUNNEL):\n",
    "    return [ (6+n)*xab(t) *(b - t) / (b - a)  + random.normalvariate(0.0,1.0) for t in range(1,tslength + 1)]    \n",
    "  else :\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Shape Time Warping at 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS20test1 = pd.DataFrame([])\n",
    "SS20test2 = pd.DataFrame([])\n",
    "SS20test3 = pd.DataFrame([])\n",
    "SS20test = pd.DataFrame([])\n",
    "\n",
    "SS20train1 = pd.DataFrame([])\n",
    "SS20train2 = pd.DataFrame([])\n",
    "SS20train3 = pd.DataFrame([])\n",
    "SS20train = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,30):\n",
    "    SS20test1 = SS20test1.append(pd.DataFrame(keoghcbfSS(1,10,20,5,25)).T)\n",
    "    SS20test2 = SS20test2.append(pd.DataFrame(keoghcbfSS(2,10,20,5,25)).T)\n",
    "    SS20test3 = SS20test3.append(pd.DataFrame(keoghcbfSS(3,10,20,5,25)).T)\n",
    "    \n",
    "    SS20test1 = SS20test1.append(pd.DataFrame(keoghcbfSS(1,1,33,65,95)).T)\n",
    "    SS20test2 = SS20test2.append(pd.DataFrame(keoghcbfSS(2,1,33,65,95)).T)\n",
    "    SS20test3 = SS20test3.append(pd.DataFrame(keoghcbfSS(3,1,33,65,95)).T)\n",
    "\n",
    "for i in range(0,240):\n",
    "    SS20test1 = SS20test1.append(pd.DataFrame(keoghcbfSS(1,16,32,32,96)).T)\n",
    "    SS20test2 = SS20test2.append(pd.DataFrame(keoghcbfSS(2,16,32,32,96)).T)\n",
    "    SS20test3 = SS20test3.append(pd.DataFrame(keoghcbfSS(3,16,32,32,96)).T)\n",
    "    \n",
    "    \n",
    "for i in range(0,10):  \n",
    "    SS20train1 = SS20train1.append(pd.DataFrame(keoghcbfSS(1,10,20,5,25)).T)\n",
    "    SS20train2 = SS20train2.append(pd.DataFrame(keoghcbfSS(2,10,20,5,25)).T)\n",
    "    SS20train3 = SS20train3.append(pd.DataFrame(keoghcbfSS(3,10,20,5,25)).T)\n",
    "    \n",
    "    SS20train1 = SS20train1.append(pd.DataFrame(keoghcbfSS(1,1,33,65,95)).T)\n",
    "    SS20train2 = SS20train2.append(pd.DataFrame(keoghcbfSS(2,1,33,65,95)).T)\n",
    "    SS20train3 = SS20train3.append(pd.DataFrame(keoghcbfSS(3,1,33,65,95)).T)\n",
    "    \n",
    "for i in range(0,80):\n",
    "    SS20train1 = SS20train1.append(pd.DataFrame(keoghcbfSS(1,16,32,32,96)).T)\n",
    "    SS20train2 = SS20train2.append(pd.DataFrame(keoghcbfSS(2,16,32,32,96)).T)\n",
    "    SS20train3 = SS20train3.append(pd.DataFrame(keoghcbfSS(3,16,32,32,96)).T)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS20test3.insert(0, 'class', 3)\n",
    "SS20test2.insert(0, 'class', 2)\n",
    "SS20test1.insert(0, 'class', 1)\n",
    "\n",
    "SS20train3.insert(0, 'class', 3)\n",
    "SS20train2.insert(0, 'class', 2)\n",
    "SS20train1.insert(0, 'class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS20train = SS20train.append(pd.DataFrame(SS20train1))\n",
    "SS20train = SS20train.append(pd.DataFrame(SS20train2))\n",
    "SS20train = SS20train.append(pd.DataFrame(SS20train3))\n",
    "\n",
    "SS20test = SS20test.append(pd.DataFrame(SS20test1))\n",
    "SS20test = SS20test.append(pd.DataFrame(SS20test2))\n",
    "SS20test = SS20test.append(pd.DataFrame(SS20test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS20test = SS20test.sample(frac=1).reset_index(drop=True)\n",
    "SS20train = SS20train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS20test.to_csv('SSTimeWarping20_TEST', sep=',', index=False, header=False)\n",
    "SS20train.to_csv('SSTimeWarping20_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Shape Time Warping at 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS40test1 = pd.DataFrame([])\n",
    "SS40test2 = pd.DataFrame([])\n",
    "SS40test3 = pd.DataFrame([])\n",
    "SS40test = pd.DataFrame([])\n",
    "\n",
    "SS40train1 = pd.DataFrame([])\n",
    "SS40train2 = pd.DataFrame([])\n",
    "SS40train3 = pd.DataFrame([])\n",
    "SS40train = pd.DataFrame([])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,60):\n",
    "    SS40test1 = SS40test1.append(pd.DataFrame(keoghcbfSS(1,10,20,5,25)).T)\n",
    "    SS40test2 = SS40test2.append(pd.DataFrame(keoghcbfSS(2,10,20,5,25)).T)\n",
    "    SS40test3 = SS40test3.append(pd.DataFrame(keoghcbfSS(3,10,20,5,25)).T)\n",
    "    \n",
    "    SS40test1 = SS40test1.append(pd.DataFrame(keoghcbfSS(1,1,33,65,95)).T)\n",
    "    SS40test2 = SS40test2.append(pd.DataFrame(keoghcbfSS(2,1,33,65,95)).T)\n",
    "    SS40test3 = SS40test3.append(pd.DataFrame(keoghcbfSS(3,1,33,65,95)).T)\n",
    "\n",
    "for i in range(0,180):\n",
    "    SS40test1 = SS40test1.append(pd.DataFrame(keoghcbfSS(1,16,32,32,96)).T)\n",
    "    SS40test2 = SS40test2.append(pd.DataFrame(keoghcbfSS(2,16,32,32,96)).T)\n",
    "    SS40test3 = SS40test3.append(pd.DataFrame(keoghcbfSS(3,16,32,32,96)).T)\n",
    "    \n",
    "    \n",
    "for i in range(0,20):\n",
    "    SS40train1 = SS40train1.append(pd.DataFrame(keoghcbfSS(1,10,20,5,25)).T)\n",
    "    SS40train2 = SS40train2.append(pd.DataFrame(keoghcbfSS(2,10,20,5,25)).T)\n",
    "    SS40train3 = SS40train3.append(pd.DataFrame(keoghcbfSS(3,10,20,5,25)).T)\n",
    "    \n",
    "    SS40train1 = SS40train1.append(pd.DataFrame(keoghcbfSS(1,1,33,65,95)).T)\n",
    "    SS40train2 = SS40train2.append(pd.DataFrame(keoghcbfSS(2,1,33,65,95)).T)\n",
    "    SS40train3 = SS40train3.append(pd.DataFrame(keoghcbfSS(3,1,33,65,95)).T)\n",
    "    \n",
    "for i in range(0,60):\n",
    "    SS40train1 = SS40train1.append(pd.DataFrame(keoghcbfSS(1,16,32,32,96)).T)\n",
    "    SS40train2 = SS40train2.append(pd.DataFrame(keoghcbfSS(2,16,32,32,96)).T)\n",
    "    SS40train3 = SS40train3.append(pd.DataFrame(keoghcbfSS(3,16,32,32,96)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS40test3.insert(0, 'class', 3)\n",
    "SS40test2.insert(0, 'class', 2)\n",
    "SS40test1.insert(0, 'class', 1)\n",
    "\n",
    "SS40train3.insert(0, 'class', 3)\n",
    "SS40train2.insert(0, 'class', 2)\n",
    "SS40train1.insert(0, 'class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS40train = SS40train.append(pd.DataFrame(SS40train1))\n",
    "SS40train = SS40train.append(pd.DataFrame(SS40train2))\n",
    "SS40train = SS40train.append(pd.DataFrame(SS40train3))\n",
    "\n",
    "SS40test = SS40test.append(pd.DataFrame(SS40test1))\n",
    "SS40test = SS40test.append(pd.DataFrame(SS40test2))\n",
    "SS40test = SS40test.append(pd.DataFrame(SS40test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS40test = SS40test.sample(frac=1).reset_index(drop=True)\n",
    "SS40train = SS40train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS40test.to_csv('SSTimeWarping40_TEST', sep=',', index=False, header=False)\n",
    "SS40train.to_csv('SSTimeWarping40_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Shape Time Warping at 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS60test1 = pd.DataFrame([])\n",
    "SS60test2 = pd.DataFrame([])\n",
    "SS60test3 = pd.DataFrame([])\n",
    "SS60test = pd.DataFrame([])\n",
    "\n",
    "SS60train1 = pd.DataFrame([])\n",
    "SS60train2 = pd.DataFrame([])\n",
    "SS60train3 = pd.DataFrame([])\n",
    "SS60train = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,90):\n",
    "    SS60test1 = SS60test1.append(pd.DataFrame(keoghcbfSS(1,10,20,5,25)).T)\n",
    "    SS60test2 = SS60test2.append(pd.DataFrame(keoghcbfSS(2,10,20,5,25)).T)\n",
    "    SS60test3 = SS60test3.append(pd.DataFrame(keoghcbfSS(3,10,20,5,25)).T)\n",
    "    \n",
    "    SS60test1 = SS60test1.append(pd.DataFrame(keoghcbfSS(1,1,33,65,95)).T)\n",
    "    SS60test2 = SS60test2.append(pd.DataFrame(keoghcbfSS(2,1,33,65,95)).T)\n",
    "    SS60test3 = SS60test3.append(pd.DataFrame(keoghcbfSS(3,1,33,65,95)).T)\n",
    "\n",
    "for i in range(0,120):\n",
    "    SS60test1 = SS60test1.append(pd.DataFrame(keoghcbfSS(1,16,32,32,96)).T)\n",
    "    SS60test2 = SS60test2.append(pd.DataFrame(keoghcbfSS(2,16,32,32,96)).T)\n",
    "    SS60test3 = SS60test3.append(pd.DataFrame(keoghcbfSS(3,16,32,32,96)).T)\n",
    "    \n",
    "    \n",
    "for i in range(0,30):\n",
    "    SS60train1 = SS60train1.append(pd.DataFrame(keoghcbfSS(1,10,20,5,25)).T)\n",
    "    SS60train2 = SS60train2.append(pd.DataFrame(keoghcbfSS(2,10,20,5,25)).T)\n",
    "    SS60train3 = SS60train3.append(pd.DataFrame(keoghcbfSS(3,10,20,5,25)).T)\n",
    "    \n",
    "    SS60train1 = SS60train1.append(pd.DataFrame(keoghcbfSS(1,1,33,65,95)).T)\n",
    "    SS60train2 = SS60train2.append(pd.DataFrame(keoghcbfSS(2,1,33,65,95)).T)\n",
    "    SS60train3 = SS60train3.append(pd.DataFrame(keoghcbfSS(3,1,33,65,95)).T)\n",
    "    \n",
    "for i in range(0,40):\n",
    "    SS60train1 = SS60train1.append(pd.DataFrame(keoghcbfSS(1,16,32,32,96)).T)\n",
    "    SS60train2 = SS60train2.append(pd.DataFrame(keoghcbfSS(2,16,32,32,96)).T)\n",
    "    SS60train3 = SS60train3.append(pd.DataFrame(keoghcbfSS(3,16,32,32,96)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS60test3.insert(0, 'class', 3)\n",
    "SS60test2.insert(0, 'class', 2)\n",
    "SS60test1.insert(0, 'class', 1)\n",
    "\n",
    "SS60train3.insert(0, 'class', 3)\n",
    "SS60train2.insert(0, 'class', 2)\n",
    "SS60train1.insert(0, 'class', 1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS60train = SS60train.append(pd.DataFrame(SS60train1))\n",
    "SS60train = SS60train.append(pd.DataFrame(SS60train2))\n",
    "SS60train = SS60train.append(pd.DataFrame(SS60train3))\n",
    "\n",
    "SS60test = SS60test.append(pd.DataFrame(SS60test1))\n",
    "SS60test = SS60test.append(pd.DataFrame(SS60test2))\n",
    "SS60test = SS60test.append(pd.DataFrame(SS60test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS60test = SS60test.sample(frac=1).reset_index(drop=True)\n",
    "SS60train = SS60train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and testing final files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS60test.to_csv('SSTimeWarping60_TEST', sep=',', index=False, header=False)\n",
    "SS60train.to_csv('SSTimeWarping60_TRAIN', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
